{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dtr.iloc[:,:-1].values\n",
    "y=dtr.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35294118 0.74371859 0.59016393 ... 0.50074516 0.23441503 0.48333333]\n",
      " [0.05882353 0.42713568 0.54098361 ... 0.39642325 0.11656704 0.16666667]\n",
      " [0.47058824 0.91959799 0.52459016 ... 0.34724292 0.25362938 0.18333333]\n",
      " ...\n",
      " [0.29411765 0.6080402  0.59016393 ... 0.390462   0.07130658 0.15      ]\n",
      " [0.05882353 0.63316583 0.49180328 ... 0.4485842  0.11571307 0.43333333]\n",
      " [0.05882353 0.46733668 0.57377049 ... 0.45305514 0.10119556 0.03333333]]\n",
      "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state = 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.T\n",
    "y_train = y_train.reshape(1, y_train.shape[0])\n",
    "x_test = X_test.T\n",
    "y_test = y_test.reshape(1, y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=x_train.shape[0]\n",
    "hidden_layer=12\n",
    "output_layer=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "W1 = np.random.uniform(-1,1,size=(hidden_layer, input_layer))\n",
    "b1 = np.zeros((hidden_layer, 1))\n",
    "W2 = np.random.uniform(-1,1,size=(output_layer, hidden_layer))\n",
    "b2 = np.zeros((output_layer, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(W1,x_train,b1,W2,b2):\n",
    "    \n",
    "    Z1 = np.dot(W1, x_train) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_main(A2,y_train):\n",
    "    \n",
    "    m = y_train.shape[1] \n",
    "    cost= np.multiply(np.log(A2), y_train) + np.multiply((1-y_train), np.log(1 - A2))\n",
    "    cost = - np.sum(cost) / m\n",
    "    cost = float(np.squeeze(cost))\n",
    "    return cost\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(W1,W2, cache, x_train, y_train):\n",
    "    m = x_train.shape[1]\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "   \n",
    "    dZ2 = A2-y_train\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, x_train.T) \n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2,\"db2\": db2}\n",
    "    \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(W1,b1,W2,b2, grads, learning_rate):\n",
    "   \n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    \n",
    "    return W1,W2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(x_train, y_train,num_iterations,W1,W2,b1,b2,learning_rate):\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(W1,x_train,b1,W2,b2)\n",
    "        cost =cost_main(A2,y_train)\n",
    "        grads = backward_propagation(W1,W2, cache, x_train, y_train)\n",
    "        W1,W2,b1,b2=gradient_descent(W1,b1,W2,b2, grads, learning_rate)\n",
    "        if i % 5 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return W1,W2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.907554\n",
      "Cost after iteration 5: 0.881852\n",
      "Cost after iteration 10: 0.858526\n",
      "Cost after iteration 15: 0.837497\n",
      "Cost after iteration 20: 0.818658\n",
      "Cost after iteration 25: 0.801880\n",
      "Cost after iteration 30: 0.787017\n",
      "Cost after iteration 35: 0.773911\n",
      "Cost after iteration 40: 0.762401\n",
      "Cost after iteration 45: 0.752327\n",
      "Cost after iteration 50: 0.743532\n",
      "Cost after iteration 55: 0.735867\n",
      "Cost after iteration 60: 0.729195\n",
      "Cost after iteration 65: 0.723387\n",
      "Cost after iteration 70: 0.718328\n",
      "Cost after iteration 75: 0.713915\n",
      "Cost after iteration 80: 0.710056\n",
      "Cost after iteration 85: 0.706671\n",
      "Cost after iteration 90: 0.703691\n",
      "Cost after iteration 95: 0.701053\n",
      "Cost after iteration 100: 0.698706\n",
      "Cost after iteration 105: 0.696605\n",
      "Cost after iteration 110: 0.694713\n",
      "Cost after iteration 115: 0.692996\n",
      "Cost after iteration 120: 0.691427\n",
      "Cost after iteration 125: 0.689983\n",
      "Cost after iteration 130: 0.688645\n",
      "Cost after iteration 135: 0.687397\n",
      "Cost after iteration 140: 0.686223\n",
      "Cost after iteration 145: 0.685114\n",
      "Cost after iteration 150: 0.684059\n",
      "Cost after iteration 155: 0.683051\n",
      "Cost after iteration 160: 0.682082\n",
      "Cost after iteration 165: 0.681148\n",
      "Cost after iteration 170: 0.680243\n",
      "Cost after iteration 175: 0.679363\n",
      "Cost after iteration 180: 0.678506\n",
      "Cost after iteration 185: 0.677668\n",
      "Cost after iteration 190: 0.676848\n",
      "Cost after iteration 195: 0.676044\n",
      "Cost after iteration 200: 0.675253\n",
      "Cost after iteration 205: 0.674474\n",
      "Cost after iteration 210: 0.673708\n",
      "Cost after iteration 215: 0.672951\n",
      "Cost after iteration 220: 0.672205\n",
      "Cost after iteration 225: 0.671468\n",
      "Cost after iteration 230: 0.670739\n",
      "Cost after iteration 235: 0.670018\n",
      "Cost after iteration 240: 0.669304\n",
      "Cost after iteration 245: 0.668598\n",
      "Cost after iteration 250: 0.667899\n",
      "Cost after iteration 255: 0.667207\n",
      "Cost after iteration 260: 0.666521\n",
      "Cost after iteration 265: 0.665841\n",
      "Cost after iteration 270: 0.665167\n",
      "Cost after iteration 275: 0.664499\n",
      "Cost after iteration 280: 0.663837\n",
      "Cost after iteration 285: 0.663181\n",
      "Cost after iteration 290: 0.662529\n",
      "Cost after iteration 295: 0.661884\n",
      "Cost after iteration 300: 0.661243\n",
      "Cost after iteration 305: 0.660607\n",
      "Cost after iteration 310: 0.659977\n",
      "Cost after iteration 315: 0.659351\n",
      "Cost after iteration 320: 0.658730\n",
      "Cost after iteration 325: 0.658114\n",
      "Cost after iteration 330: 0.657502\n",
      "Cost after iteration 335: 0.656895\n",
      "Cost after iteration 340: 0.656293\n",
      "Cost after iteration 345: 0.655695\n",
      "Cost after iteration 350: 0.655101\n",
      "Cost after iteration 355: 0.654512\n",
      "Cost after iteration 360: 0.653927\n",
      "Cost after iteration 365: 0.653346\n",
      "Cost after iteration 370: 0.652769\n",
      "Cost after iteration 375: 0.652196\n",
      "Cost after iteration 380: 0.651628\n",
      "Cost after iteration 385: 0.651063\n",
      "Cost after iteration 390: 0.650501\n",
      "Cost after iteration 395: 0.649944\n",
      "Cost after iteration 400: 0.649391\n",
      "Cost after iteration 405: 0.648841\n",
      "Cost after iteration 410: 0.648295\n",
      "Cost after iteration 415: 0.647752\n",
      "Cost after iteration 420: 0.647213\n",
      "Cost after iteration 425: 0.646677\n",
      "Cost after iteration 430: 0.646145\n",
      "Cost after iteration 435: 0.645616\n",
      "Cost after iteration 440: 0.645091\n",
      "Cost after iteration 445: 0.644569\n",
      "Cost after iteration 450: 0.644050\n",
      "Cost after iteration 455: 0.643534\n",
      "Cost after iteration 460: 0.643021\n",
      "Cost after iteration 465: 0.642512\n",
      "Cost after iteration 470: 0.642005\n",
      "Cost after iteration 475: 0.641502\n",
      "Cost after iteration 480: 0.641002\n",
      "Cost after iteration 485: 0.640504\n",
      "Cost after iteration 490: 0.640010\n",
      "Cost after iteration 495: 0.639518\n",
      "Cost after iteration 500: 0.639029\n",
      "Cost after iteration 505: 0.638543\n",
      "Cost after iteration 510: 0.638060\n",
      "Cost after iteration 515: 0.637579\n",
      "Cost after iteration 520: 0.637102\n",
      "Cost after iteration 525: 0.636626\n",
      "Cost after iteration 530: 0.636154\n",
      "Cost after iteration 535: 0.635684\n",
      "Cost after iteration 540: 0.635216\n",
      "Cost after iteration 545: 0.634751\n",
      "Cost after iteration 550: 0.634289\n",
      "Cost after iteration 555: 0.633829\n",
      "Cost after iteration 560: 0.633371\n",
      "Cost after iteration 565: 0.632916\n",
      "Cost after iteration 570: 0.632463\n",
      "Cost after iteration 575: 0.632013\n",
      "Cost after iteration 580: 0.631564\n",
      "Cost after iteration 585: 0.631118\n",
      "Cost after iteration 590: 0.630675\n",
      "Cost after iteration 595: 0.630233\n",
      "Cost after iteration 600: 0.629794\n",
      "Cost after iteration 605: 0.629357\n",
      "Cost after iteration 610: 0.628922\n",
      "Cost after iteration 615: 0.628489\n",
      "Cost after iteration 620: 0.628058\n",
      "Cost after iteration 625: 0.627629\n",
      "Cost after iteration 630: 0.627202\n",
      "Cost after iteration 635: 0.626778\n",
      "Cost after iteration 640: 0.626355\n",
      "Cost after iteration 645: 0.625934\n",
      "Cost after iteration 650: 0.625515\n",
      "Cost after iteration 655: 0.625099\n",
      "Cost after iteration 660: 0.624684\n",
      "Cost after iteration 665: 0.624270\n",
      "Cost after iteration 670: 0.623859\n",
      "Cost after iteration 675: 0.623450\n",
      "Cost after iteration 680: 0.623042\n",
      "Cost after iteration 685: 0.622636\n",
      "Cost after iteration 690: 0.622232\n",
      "Cost after iteration 695: 0.621830\n",
      "Cost after iteration 700: 0.621429\n",
      "Cost after iteration 705: 0.621030\n",
      "Cost after iteration 710: 0.620633\n",
      "Cost after iteration 715: 0.620238\n",
      "Cost after iteration 720: 0.619844\n",
      "Cost after iteration 725: 0.619452\n",
      "Cost after iteration 730: 0.619061\n",
      "Cost after iteration 735: 0.618672\n",
      "Cost after iteration 740: 0.618285\n",
      "Cost after iteration 745: 0.617899\n",
      "Cost after iteration 750: 0.617514\n",
      "Cost after iteration 755: 0.617132\n",
      "Cost after iteration 760: 0.616750\n",
      "Cost after iteration 765: 0.616371\n",
      "Cost after iteration 770: 0.615993\n",
      "Cost after iteration 775: 0.615616\n",
      "Cost after iteration 780: 0.615241\n",
      "Cost after iteration 785: 0.614867\n",
      "Cost after iteration 790: 0.614494\n",
      "Cost after iteration 795: 0.614123\n",
      "Cost after iteration 800: 0.613754\n",
      "Cost after iteration 805: 0.613385\n",
      "Cost after iteration 810: 0.613019\n",
      "Cost after iteration 815: 0.612653\n",
      "Cost after iteration 820: 0.612289\n",
      "Cost after iteration 825: 0.611926\n",
      "Cost after iteration 830: 0.611565\n",
      "Cost after iteration 835: 0.611204\n",
      "Cost after iteration 840: 0.610846\n",
      "Cost after iteration 845: 0.610488\n",
      "Cost after iteration 850: 0.610132\n",
      "Cost after iteration 855: 0.609777\n",
      "Cost after iteration 860: 0.609423\n",
      "Cost after iteration 865: 0.609070\n",
      "Cost after iteration 870: 0.608719\n",
      "Cost after iteration 875: 0.608369\n",
      "Cost after iteration 880: 0.608020\n",
      "Cost after iteration 885: 0.607672\n",
      "Cost after iteration 890: 0.607326\n",
      "Cost after iteration 895: 0.606980\n",
      "Cost after iteration 900: 0.606636\n",
      "Cost after iteration 905: 0.606293\n",
      "Cost after iteration 910: 0.605951\n",
      "Cost after iteration 915: 0.605610\n",
      "Cost after iteration 920: 0.605270\n",
      "Cost after iteration 925: 0.604932\n",
      "Cost after iteration 930: 0.604594\n",
      "Cost after iteration 935: 0.604258\n",
      "Cost after iteration 940: 0.603923\n",
      "Cost after iteration 945: 0.603588\n",
      "Cost after iteration 950: 0.603255\n",
      "Cost after iteration 955: 0.602923\n",
      "Cost after iteration 960: 0.602592\n",
      "Cost after iteration 965: 0.602262\n",
      "Cost after iteration 970: 0.601933\n",
      "Cost after iteration 975: 0.601605\n",
      "Cost after iteration 980: 0.601278\n",
      "Cost after iteration 985: 0.600952\n",
      "Cost after iteration 990: 0.600627\n",
      "Cost after iteration 995: 0.600303\n",
      "Cost after iteration 1000: 0.599981\n",
      "Cost after iteration 1005: 0.599659\n",
      "Cost after iteration 1010: 0.599338\n",
      "Cost after iteration 1015: 0.599017\n",
      "Cost after iteration 1020: 0.598698\n",
      "Cost after iteration 1025: 0.598380\n",
      "Cost after iteration 1030: 0.598063\n",
      "Cost after iteration 1035: 0.597747\n",
      "Cost after iteration 1040: 0.597431\n",
      "Cost after iteration 1045: 0.597117\n",
      "Cost after iteration 1050: 0.596804\n",
      "Cost after iteration 1055: 0.596491\n",
      "Cost after iteration 1060: 0.596179\n",
      "Cost after iteration 1065: 0.595868\n",
      "Cost after iteration 1070: 0.595559\n",
      "Cost after iteration 1075: 0.595249\n",
      "Cost after iteration 1080: 0.594941\n",
      "Cost after iteration 1085: 0.594634\n",
      "Cost after iteration 1090: 0.594328\n",
      "Cost after iteration 1095: 0.594022\n",
      "Cost after iteration 1100: 0.593717\n",
      "Cost after iteration 1105: 0.593414\n",
      "Cost after iteration 1110: 0.593111\n",
      "Cost after iteration 1115: 0.592808\n",
      "Cost after iteration 1120: 0.592507\n",
      "Cost after iteration 1125: 0.592207\n",
      "Cost after iteration 1130: 0.591907\n",
      "Cost after iteration 1135: 0.591608\n",
      "Cost after iteration 1140: 0.591310\n",
      "Cost after iteration 1145: 0.591013\n",
      "Cost after iteration 1150: 0.590716\n",
      "Cost after iteration 1155: 0.590421\n",
      "Cost after iteration 1160: 0.590126\n",
      "Cost after iteration 1165: 0.589832\n",
      "Cost after iteration 1170: 0.589538\n",
      "Cost after iteration 1175: 0.589246\n",
      "Cost after iteration 1180: 0.588954\n",
      "Cost after iteration 1185: 0.588663\n",
      "Cost after iteration 1190: 0.588373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1195: 0.588084\n",
      "Cost after iteration 1200: 0.587795\n",
      "Cost after iteration 1205: 0.587507\n",
      "Cost after iteration 1210: 0.587220\n",
      "Cost after iteration 1215: 0.586933\n",
      "Cost after iteration 1220: 0.586648\n",
      "Cost after iteration 1225: 0.586363\n",
      "Cost after iteration 1230: 0.586079\n",
      "Cost after iteration 1235: 0.585795\n",
      "Cost after iteration 1240: 0.585512\n",
      "Cost after iteration 1245: 0.585230\n",
      "Cost after iteration 1250: 0.584949\n",
      "Cost after iteration 1255: 0.584668\n",
      "Cost after iteration 1260: 0.584388\n",
      "Cost after iteration 1265: 0.584109\n",
      "Cost after iteration 1270: 0.583831\n",
      "Cost after iteration 1275: 0.583553\n",
      "Cost after iteration 1280: 0.583276\n",
      "Cost after iteration 1285: 0.583000\n",
      "Cost after iteration 1290: 0.582724\n",
      "Cost after iteration 1295: 0.582449\n",
      "Cost after iteration 1300: 0.582175\n",
      "Cost after iteration 1305: 0.581901\n",
      "Cost after iteration 1310: 0.581628\n",
      "Cost after iteration 1315: 0.581356\n",
      "Cost after iteration 1320: 0.581084\n",
      "Cost after iteration 1325: 0.580813\n",
      "Cost after iteration 1330: 0.580543\n",
      "Cost after iteration 1335: 0.580273\n",
      "Cost after iteration 1340: 0.580004\n",
      "Cost after iteration 1345: 0.579736\n",
      "Cost after iteration 1350: 0.579469\n",
      "Cost after iteration 1355: 0.579202\n",
      "Cost after iteration 1360: 0.578935\n",
      "Cost after iteration 1365: 0.578670\n",
      "Cost after iteration 1370: 0.578405\n",
      "Cost after iteration 1375: 0.578140\n",
      "Cost after iteration 1380: 0.577876\n",
      "Cost after iteration 1385: 0.577613\n",
      "Cost after iteration 1390: 0.577351\n",
      "Cost after iteration 1395: 0.577089\n",
      "Cost after iteration 1400: 0.576828\n",
      "Cost after iteration 1405: 0.576567\n",
      "Cost after iteration 1410: 0.576307\n",
      "Cost after iteration 1415: 0.576048\n",
      "Cost after iteration 1420: 0.575789\n",
      "Cost after iteration 1425: 0.575531\n",
      "Cost after iteration 1430: 0.575274\n",
      "Cost after iteration 1435: 0.575017\n",
      "Cost after iteration 1440: 0.574761\n",
      "Cost after iteration 1445: 0.574505\n",
      "Cost after iteration 1450: 0.574250\n",
      "Cost after iteration 1455: 0.573996\n",
      "Cost after iteration 1460: 0.573742\n",
      "Cost after iteration 1465: 0.573489\n",
      "Cost after iteration 1470: 0.573236\n",
      "Cost after iteration 1475: 0.572984\n",
      "Cost after iteration 1480: 0.572732\n",
      "Cost after iteration 1485: 0.572482\n",
      "Cost after iteration 1490: 0.572231\n",
      "Cost after iteration 1495: 0.571982\n",
      "Cost after iteration 1500: 0.571733\n",
      "Cost after iteration 1505: 0.571484\n",
      "Cost after iteration 1510: 0.571236\n",
      "Cost after iteration 1515: 0.570989\n",
      "Cost after iteration 1520: 0.570742\n",
      "Cost after iteration 1525: 0.570496\n",
      "Cost after iteration 1530: 0.570251\n",
      "Cost after iteration 1535: 0.570006\n",
      "Cost after iteration 1540: 0.569761\n",
      "Cost after iteration 1545: 0.569517\n",
      "Cost after iteration 1550: 0.569274\n",
      "Cost after iteration 1555: 0.569031\n",
      "Cost after iteration 1560: 0.568789\n",
      "Cost after iteration 1565: 0.568548\n",
      "Cost after iteration 1570: 0.568307\n",
      "Cost after iteration 1575: 0.568066\n",
      "Cost after iteration 1580: 0.567826\n",
      "Cost after iteration 1585: 0.567587\n",
      "Cost after iteration 1590: 0.567348\n",
      "Cost after iteration 1595: 0.567110\n",
      "Cost after iteration 1600: 0.566873\n",
      "Cost after iteration 1605: 0.566635\n",
      "Cost after iteration 1610: 0.566399\n",
      "Cost after iteration 1615: 0.566163\n",
      "Cost after iteration 1620: 0.565927\n",
      "Cost after iteration 1625: 0.565693\n",
      "Cost after iteration 1630: 0.565458\n",
      "Cost after iteration 1635: 0.565224\n",
      "Cost after iteration 1640: 0.564991\n",
      "Cost after iteration 1645: 0.564758\n",
      "Cost after iteration 1650: 0.564526\n",
      "Cost after iteration 1655: 0.564295\n",
      "Cost after iteration 1660: 0.564063\n",
      "Cost after iteration 1665: 0.563833\n",
      "Cost after iteration 1670: 0.563603\n",
      "Cost after iteration 1675: 0.563373\n",
      "Cost after iteration 1680: 0.563144\n",
      "Cost after iteration 1685: 0.562916\n",
      "Cost after iteration 1690: 0.562688\n",
      "Cost after iteration 1695: 0.562461\n",
      "Cost after iteration 1700: 0.562234\n",
      "Cost after iteration 1705: 0.562008\n",
      "Cost after iteration 1710: 0.561782\n",
      "Cost after iteration 1715: 0.561557\n",
      "Cost after iteration 1720: 0.561332\n",
      "Cost after iteration 1725: 0.561108\n",
      "Cost after iteration 1730: 0.560884\n",
      "Cost after iteration 1735: 0.560661\n",
      "Cost after iteration 1740: 0.560438\n",
      "Cost after iteration 1745: 0.560216\n",
      "Cost after iteration 1750: 0.559994\n",
      "Cost after iteration 1755: 0.559773\n",
      "Cost after iteration 1760: 0.559553\n",
      "Cost after iteration 1765: 0.559332\n",
      "Cost after iteration 1770: 0.559113\n",
      "Cost after iteration 1775: 0.558894\n",
      "Cost after iteration 1780: 0.558675\n",
      "Cost after iteration 1785: 0.558457\n",
      "Cost after iteration 1790: 0.558240\n",
      "Cost after iteration 1795: 0.558023\n",
      "Cost after iteration 1800: 0.557806\n",
      "Cost after iteration 1805: 0.557590\n",
      "Cost after iteration 1810: 0.557375\n",
      "Cost after iteration 1815: 0.557160\n",
      "Cost after iteration 1820: 0.556945\n",
      "Cost after iteration 1825: 0.556731\n",
      "Cost after iteration 1830: 0.556517\n",
      "Cost after iteration 1835: 0.556304\n",
      "Cost after iteration 1840: 0.556092\n",
      "Cost after iteration 1845: 0.555880\n",
      "Cost after iteration 1850: 0.555668\n",
      "Cost after iteration 1855: 0.555457\n",
      "Cost after iteration 1860: 0.555247\n",
      "Cost after iteration 1865: 0.555037\n",
      "Cost after iteration 1870: 0.554827\n",
      "Cost after iteration 1875: 0.554618\n",
      "Cost after iteration 1880: 0.554409\n",
      "Cost after iteration 1885: 0.554201\n",
      "Cost after iteration 1890: 0.553994\n",
      "Cost after iteration 1895: 0.553787\n",
      "Cost after iteration 1900: 0.553580\n",
      "Cost after iteration 1905: 0.553374\n",
      "Cost after iteration 1910: 0.553168\n",
      "Cost after iteration 1915: 0.552963\n",
      "Cost after iteration 1920: 0.552758\n",
      "Cost after iteration 1925: 0.552554\n",
      "Cost after iteration 1930: 0.552350\n",
      "Cost after iteration 1935: 0.552147\n",
      "Cost after iteration 1940: 0.551944\n",
      "Cost after iteration 1945: 0.551742\n",
      "Cost after iteration 1950: 0.551540\n",
      "Cost after iteration 1955: 0.551338\n",
      "Cost after iteration 1960: 0.551138\n",
      "Cost after iteration 1965: 0.550937\n",
      "Cost after iteration 1970: 0.550737\n",
      "Cost after iteration 1975: 0.550538\n",
      "Cost after iteration 1980: 0.550339\n",
      "Cost after iteration 1985: 0.550140\n",
      "Cost after iteration 1990: 0.549942\n",
      "Cost after iteration 1995: 0.549744\n",
      "Cost after iteration 2000: 0.549547\n",
      "Cost after iteration 2005: 0.549350\n",
      "Cost after iteration 2010: 0.549154\n",
      "Cost after iteration 2015: 0.548958\n",
      "Cost after iteration 2020: 0.548763\n",
      "Cost after iteration 2025: 0.548568\n",
      "Cost after iteration 2030: 0.548374\n",
      "Cost after iteration 2035: 0.548180\n",
      "Cost after iteration 2040: 0.547987\n",
      "Cost after iteration 2045: 0.547794\n",
      "Cost after iteration 2050: 0.547601\n",
      "Cost after iteration 2055: 0.547409\n",
      "Cost after iteration 2060: 0.547217\n",
      "Cost after iteration 2065: 0.547026\n",
      "Cost after iteration 2070: 0.546835\n",
      "Cost after iteration 2075: 0.546645\n",
      "Cost after iteration 2080: 0.546455\n",
      "Cost after iteration 2085: 0.546266\n",
      "Cost after iteration 2090: 0.546077\n",
      "Cost after iteration 2095: 0.545888\n",
      "Cost after iteration 2100: 0.545700\n",
      "Cost after iteration 2105: 0.545513\n",
      "Cost after iteration 2110: 0.545326\n",
      "Cost after iteration 2115: 0.545139\n",
      "Cost after iteration 2120: 0.544953\n",
      "Cost after iteration 2125: 0.544767\n",
      "Cost after iteration 2130: 0.544582\n",
      "Cost after iteration 2135: 0.544397\n",
      "Cost after iteration 2140: 0.544212\n",
      "Cost after iteration 2145: 0.544028\n",
      "Cost after iteration 2150: 0.543845\n",
      "Cost after iteration 2155: 0.543661\n",
      "Cost after iteration 2160: 0.543479\n",
      "Cost after iteration 2165: 0.543296\n",
      "Cost after iteration 2170: 0.543115\n",
      "Cost after iteration 2175: 0.542933\n",
      "Cost after iteration 2180: 0.542752\n",
      "Cost after iteration 2185: 0.542572\n",
      "Cost after iteration 2190: 0.542392\n",
      "Cost after iteration 2195: 0.542212\n",
      "Cost after iteration 2200: 0.542033\n",
      "Cost after iteration 2205: 0.541854\n",
      "Cost after iteration 2210: 0.541675\n",
      "Cost after iteration 2215: 0.541498\n",
      "Cost after iteration 2220: 0.541320\n",
      "Cost after iteration 2225: 0.541143\n",
      "Cost after iteration 2230: 0.540966\n",
      "Cost after iteration 2235: 0.540790\n",
      "Cost after iteration 2240: 0.540614\n",
      "Cost after iteration 2245: 0.540439\n",
      "Cost after iteration 2250: 0.540264\n",
      "Cost after iteration 2255: 0.540089\n",
      "Cost after iteration 2260: 0.539915\n",
      "Cost after iteration 2265: 0.539741\n",
      "Cost after iteration 2270: 0.539568\n",
      "Cost after iteration 2275: 0.539395\n",
      "Cost after iteration 2280: 0.539223\n",
      "Cost after iteration 2285: 0.539051\n",
      "Cost after iteration 2290: 0.538879\n",
      "Cost after iteration 2295: 0.538708\n",
      "Cost after iteration 2300: 0.538537\n",
      "Cost after iteration 2305: 0.538367\n",
      "Cost after iteration 2310: 0.538197\n",
      "Cost after iteration 2315: 0.538027\n",
      "Cost after iteration 2320: 0.537858\n",
      "Cost after iteration 2325: 0.537689\n",
      "Cost after iteration 2330: 0.537521\n",
      "Cost after iteration 2335: 0.537353\n",
      "Cost after iteration 2340: 0.537185\n",
      "Cost after iteration 2345: 0.537018\n",
      "Cost after iteration 2350: 0.536852\n",
      "Cost after iteration 2355: 0.536685\n",
      "Cost after iteration 2360: 0.536519\n",
      "Cost after iteration 2365: 0.536354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 2370: 0.536189\n",
      "Cost after iteration 2375: 0.536024\n",
      "Cost after iteration 2380: 0.535860\n",
      "Cost after iteration 2385: 0.535696\n",
      "Cost after iteration 2390: 0.535533\n",
      "Cost after iteration 2395: 0.535369\n",
      "Cost after iteration 2400: 0.535207\n",
      "Cost after iteration 2405: 0.535045\n",
      "Cost after iteration 2410: 0.534883\n",
      "Cost after iteration 2415: 0.534721\n",
      "Cost after iteration 2420: 0.534560\n",
      "Cost after iteration 2425: 0.534399\n",
      "Cost after iteration 2430: 0.534239\n",
      "Cost after iteration 2435: 0.534079\n",
      "Cost after iteration 2440: 0.533920\n",
      "Cost after iteration 2445: 0.533760\n",
      "Cost after iteration 2450: 0.533602\n",
      "Cost after iteration 2455: 0.533443\n",
      "Cost after iteration 2460: 0.533285\n",
      "Cost after iteration 2465: 0.533128\n",
      "Cost after iteration 2470: 0.532970\n",
      "Cost after iteration 2475: 0.532814\n",
      "Cost after iteration 2480: 0.532657\n",
      "Cost after iteration 2485: 0.532501\n",
      "Cost after iteration 2490: 0.532345\n",
      "Cost after iteration 2495: 0.532190\n",
      "Cost after iteration 2500: 0.532035\n",
      "Cost after iteration 2505: 0.531881\n",
      "Cost after iteration 2510: 0.531727\n",
      "Cost after iteration 2515: 0.531573\n",
      "Cost after iteration 2520: 0.531419\n",
      "Cost after iteration 2525: 0.531266\n",
      "Cost after iteration 2530: 0.531114\n",
      "Cost after iteration 2535: 0.530962\n",
      "Cost after iteration 2540: 0.530810\n",
      "Cost after iteration 2545: 0.530658\n",
      "Cost after iteration 2550: 0.530507\n",
      "Cost after iteration 2555: 0.530356\n",
      "Cost after iteration 2560: 0.530206\n",
      "Cost after iteration 2565: 0.530056\n",
      "Cost after iteration 2570: 0.529906\n",
      "Cost after iteration 2575: 0.529757\n",
      "Cost after iteration 2580: 0.529608\n",
      "Cost after iteration 2585: 0.529459\n",
      "Cost after iteration 2590: 0.529311\n",
      "Cost after iteration 2595: 0.529163\n",
      "Cost after iteration 2600: 0.529016\n",
      "Cost after iteration 2605: 0.528869\n",
      "Cost after iteration 2610: 0.528722\n",
      "Cost after iteration 2615: 0.528576\n",
      "Cost after iteration 2620: 0.528430\n",
      "Cost after iteration 2625: 0.528284\n",
      "Cost after iteration 2630: 0.528139\n",
      "Cost after iteration 2635: 0.527994\n",
      "Cost after iteration 2640: 0.527849\n",
      "Cost after iteration 2645: 0.527705\n",
      "Cost after iteration 2650: 0.527561\n",
      "Cost after iteration 2655: 0.527418\n",
      "Cost after iteration 2660: 0.527275\n",
      "Cost after iteration 2665: 0.527132\n",
      "Cost after iteration 2670: 0.526989\n",
      "Cost after iteration 2675: 0.526847\n",
      "Cost after iteration 2680: 0.526706\n",
      "Cost after iteration 2685: 0.526564\n",
      "Cost after iteration 2690: 0.526423\n",
      "Cost after iteration 2695: 0.526282\n",
      "Cost after iteration 2700: 0.526142\n",
      "Cost after iteration 2705: 0.526002\n",
      "Cost after iteration 2710: 0.525862\n",
      "Cost after iteration 2715: 0.525723\n",
      "Cost after iteration 2720: 0.525584\n",
      "Cost after iteration 2725: 0.525446\n",
      "Cost after iteration 2730: 0.525307\n",
      "Cost after iteration 2735: 0.525169\n",
      "Cost after iteration 2740: 0.525032\n",
      "Cost after iteration 2745: 0.524895\n",
      "Cost after iteration 2750: 0.524758\n",
      "Cost after iteration 2755: 0.524621\n",
      "Cost after iteration 2760: 0.524485\n",
      "Cost after iteration 2765: 0.524349\n",
      "Cost after iteration 2770: 0.524214\n",
      "Cost after iteration 2775: 0.524078\n",
      "Cost after iteration 2780: 0.523944\n",
      "Cost after iteration 2785: 0.523809\n",
      "Cost after iteration 2790: 0.523675\n",
      "Cost after iteration 2795: 0.523541\n",
      "Cost after iteration 2800: 0.523407\n",
      "Cost after iteration 2805: 0.523274\n",
      "Cost after iteration 2810: 0.523141\n",
      "Cost after iteration 2815: 0.523009\n",
      "Cost after iteration 2820: 0.522877\n",
      "Cost after iteration 2825: 0.522745\n",
      "Cost after iteration 2830: 0.522613\n",
      "Cost after iteration 2835: 0.522482\n",
      "Cost after iteration 2840: 0.522351\n",
      "Cost after iteration 2845: 0.522220\n",
      "Cost after iteration 2850: 0.522090\n",
      "Cost after iteration 2855: 0.521960\n",
      "Cost after iteration 2860: 0.521831\n",
      "Cost after iteration 2865: 0.521701\n",
      "Cost after iteration 2870: 0.521572\n",
      "Cost after iteration 2875: 0.521444\n",
      "Cost after iteration 2880: 0.521315\n",
      "Cost after iteration 2885: 0.521187\n",
      "Cost after iteration 2890: 0.521060\n",
      "Cost after iteration 2895: 0.520932\n",
      "Cost after iteration 2900: 0.520805\n",
      "Cost after iteration 2905: 0.520679\n",
      "Cost after iteration 2910: 0.520552\n",
      "Cost after iteration 2915: 0.520426\n",
      "Cost after iteration 2920: 0.520300\n",
      "Cost after iteration 2925: 0.520175\n",
      "Cost after iteration 2930: 0.520050\n",
      "Cost after iteration 2935: 0.519925\n",
      "Cost after iteration 2940: 0.519800\n",
      "Cost after iteration 2945: 0.519676\n",
      "Cost after iteration 2950: 0.519552\n",
      "Cost after iteration 2955: 0.519428\n",
      "Cost after iteration 2960: 0.519305\n",
      "Cost after iteration 2965: 0.519182\n",
      "Cost after iteration 2970: 0.519059\n",
      "Cost after iteration 2975: 0.518937\n",
      "Cost after iteration 2980: 0.518815\n",
      "Cost after iteration 2985: 0.518693\n",
      "Cost after iteration 2990: 0.518572\n",
      "Cost after iteration 2995: 0.518451\n"
     ]
    }
   ],
   "source": [
    "W1,W2,b1,b2=neural_network_model(x_train, y_train,3000,W1,W2,b1,b2,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(W1,W2,b1,b2,x_train):\n",
    "    A2, cache = forward_propagation(W1,x_train,b1,W2,b2)\n",
    "    predictions = np.round(A2)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 76%\n",
      "Accuracy Test: 76%\n"
     ]
    }
   ],
   "source": [
    "predictions =prediction(W1,W2,b1,b2,x_train)\n",
    "print ('Accuracy Train: %d' % float((np.dot(y_train, predictions.T) + np.dot(1 - y_train, 1 - predictions.T))/float(y_train.size)*100) + '%')\n",
    "predictions = prediction(W1,W2,b1,b2,x_test)\n",
    "print ('Accuracy Test: %d' % float((np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))/float(y_test.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
